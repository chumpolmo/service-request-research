from fastapi import FastAPI, Request
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForTokenClassification
import torch
import torch.nn.functional as F
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3001"],  # ‡∏´‡∏£‡∏∑‡∏≠ ["*"] ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å origin (‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‡πÇ‡∏´‡∏•‡∏î Model ‡πÅ‡∏•‡∏∞ Tokenizer ‡∏ó‡∏µ‡πà fine-tune ‡πÅ‡∏•‡πâ‡∏ß
model_path = "../testing/output-mbert/checkpoint-265"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô path ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ù‡∏∂‡∏Å‡πÄ‡∏≠‡∏á
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForTokenClassification.from_pretrained(model_path)

class InputText(BaseModel):
    text: str

@app.post("/ner")
async def ner(input_text: InputText):
    text = input_text.text
    inputs = tokenizer(text, return_tensors="pt")
    outputs = model(**inputs)

    logits = outputs.logits  # [batch_size, seq_len, num_labels]
    probs = F.softmax(logits, dim=-1)  # Convert logits to probabilities
    predictions = torch.argmax(logits, dim=-1)  # [batch_size, seq_len]

    tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"][0])
    labels = [model.config.id2label[label_id] for label_id in predictions[0].tolist()]
    probs_list = probs[0].tolist()  # [seq_len, num_labels]

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ token
    token_results = []
    for token, label, prob_vec in zip(tokens, labels, probs_list):
        if label != "O":  # üî• ‡πÄ‡∏û‡∏¥‡πà‡∏° filter ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ entity
            confidence = max(prob_vec)
            token_result = {
                "token": token,
                "label": label,
                "confidence": max(prob_vec),
                "all_probs": {model.config.id2label[i]: float(prob) for i, prob in enumerate(prob_vec)}
            }
            token_results.append(token_result)

    return {
        "text": text,
        "entities": token_results,
        "labels": model.config.id2label  # ‡πÅ‡∏ñ‡∏° mapping id2label ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    }